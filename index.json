
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"I am a final year PhD student in EECS at MIT. I am currently applying for faculty positions in Statistics and Computer Science (as of Fall 2023). I am extremely fortunate to be advised by Caroline Uhler and David Sontag.\nNy research focuses on building the statistical and computational foundations for AI-driven decision-making in scientific applications, and I work on methods for causal structure learning, experimental design, and causal representation learning.\nAs a member of the Eric and Wendy Schmidt Center, my work is grounded by problems in cellular biology, e.g. predicting the effect of a drug in novel cancer cell lines.\nTeaching and Organizing. I really enjoy teaching, mentoring, and organizing academic initiatives. Check out the lecture notes and recordings for the causality class that I developed for MITâ€™s 2023 January term, and join the ongoing talk series, Causality, Abstraction, Reasoning, and Extrapolation (CARE), that I am co-organizing.\nCommunication. I believe that communicating technical material is one of the most important and most challenging activities in a research career. As a member of the EECS Communication Lab, I coach researchers on how to communicate more effectively.\nSoftware. I like writing good, easy-to-use code (when time permits ðŸ˜…), and I am the main developer of causaldag, a Python package for creating, manipulating, and learning causal graphical models. Shoot me an email to chat about the package or my work!\nOther materials. I try to keep an up-to-date repository of slides from my talks and posters from conferences and workshops.\n","date":1702166400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1702166400,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/chandler-squires/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/chandler-squires/","section":"authors","summary":"I am a final year PhD student in EECS at MIT. I am currently applying for faculty positions in Statistics and Computer Science (as of Fall 2023). I am extremely fortunate to be advised by Caroline Uhler and David Sontag.","tags":null,"title":"Chandler Squires","type":"authors"},{"authors":null,"categories":null,"content":"In this tutorial, Iâ€™ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, â€¦","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, Iâ€™ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices â€¦","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":"Slides can be added in a few ways:\nCreate slides using Academicâ€™s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["Jiaqi Zhang","Kristjan Greenewald","Chandler Squires","Akash Srivastava","Karthikeyan Shanmugam","Caroline Uhler"],"categories":null,"content":"","date":1702166400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1702166400,"objectID":"4e0265d5ca617fd0abba599abd7a8440","permalink":"/publication/2023/identifiability-guarantees-for-causal-disentanglement-from-soft-interventions/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2023/identifiability-guarantees-for-causal-disentanglement-from-soft-interventions/","section":"publication","summary":"Causal disentanglement aims to uncover a representation of data using latent variables that are interrelated through a causal model. Such a representation is identifiable if the latent model that explains the data is unique. In this paper, we focus on the scenario where unpaired observational and interventional data are available, with each intervention changing the mechanism of a latent variable. When the causal variables are fully observed, statistically consistent algorithms have been developed to identify the causal model under faithfulness assumptions. We here show that identifiability can still be achieved with unobserved causal variables, given a generalized notion of faithfulness. Our results guarantee that we can recover the latent causal model up to an equivalence class and predict the effect of unseen combinations of interventions, in the limit of infinite data. We implement our causal disentanglement framework by developing an autoencoding variational Bayes algorithm and apply it to the problem of predicting combinatorial perturbation effects in genomics.","tags":["Causal Representation Learning","Interventions"],"title":"Identifiability Guarantees for Causal Disentanglement from Soft Interventions","type":"publication"},{"authors":["Nils Sturma","Chandler Squires","Mathias Drton","Caroline Uhler"],"categories":null,"content":"","date":1702166400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1702166400,"objectID":"525579f2d382e1e8e8dbb651c27203e3","permalink":"/publication/2023/unpaired-multi-domain-causal-representation-learning/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2023/unpaired-multi-domain-causal-representation-learning/","section":"publication","summary":"The goal of causal representation learning is to find a representation of data that consists of causally related latent variables. We consider a setup where one has access to data from multiple domains that potentially share a causal representation. Crucially, observations in different domains are assumed to be unpaired, that is, we only observe the marginal distribution in each domain but not their joint distribution. In this paper, we give sufficient conditions for identifiability of the joint distribution and the shared causal graph in a linear setup. Identifiability holds if we can uniquely recover the joint distribution and the shared causal representation from the marginal distributions in each domain. We transform our identifiability results into a practical method to recover the shared latent causal graph. Moreover, we study how multiple domains reduce errors in falsely detecting shared causal variables in the finite data setting.","tags":["Causal Representation Learning","Multi-modal"],"title":"Unpaired Multi-Domain Causal Representation Learning","type":"publication"},{"authors":["Jiaqi Zhang","Louis Cammarata","Chandler Squires","Themistoklis Sapsis","Caroline Uhler"],"categories":null,"content":"","date":1696204800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696204800,"objectID":"5888e3e297738929f84a3a03dc99ace7","permalink":"/publication/2023/active-learning-for-optimal-intervention-design/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2023/active-learning-for-optimal-intervention-design/","section":"publication","summary":"An important problem across disciplines is the discovery of interventions that produce a desired outcome. When the space of possible interventions is large, making an exhaustive search infeasible, experimental design strategies are needed. In this context, encoding the causal relationships between the variables, and thus the effect of interventions on the system, is critical in order to identify desirable interventions efficiently. We develop an iterative causal method to identify optimal interventions, as measured by the discrepancy between the post-interventional mean of the distribution and a desired target mean. We formulate an active learning strategy that uses the samples obtained so far from different interventions to update the belief about the underlying causal model, as well as to identify samples that are most informative about optimal interventions and thus should be acquired in the next batch. The approach employs a Bayesian update for the causal model and prioritizes interventions using a carefully designed, causally informed acquisition function. This acquisition function is evaluated in closed form, allowing for efficient optimization. The resulting algorithms are theoretically grounded with information-theoretic bounds and provable consistency results. We illustrate the method on both synthetic data and real-world biological data, namely gene expression data from Perturb-CITE-seq experiments, to identify optimal perturbations that induce a specific cell state transition; the proposed causal approach is observed to achieve better sample efficiency compared to several baselines. In both cases we observe that the causally informed acquisition function notably outperforms existing criteria allowing for optimal intervention design with significantly less experiments.","tags":["Experimental Design"],"title":"Active Learning for Optimal Intervention Design in Causal Models","type":"publication"},{"authors":["Chandler Squires","Anna Seigal","Salil Bhate","Caroline Uhler"],"categories":null,"content":"","date":1689897600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689897600,"objectID":"9817c71b8ee38ca0519e5e30e665122c","permalink":"/publication/2023/linear-causal-disentanglement-via-interventions/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2023/linear-causal-disentanglement-via-interventions/","section":"publication","summary":"Causal disentanglement seeks a representation of data involving latent variables that relate to one another via a causal model. A representation is identifiable if both the latent model and the transformation from latent to observed variables are unique. In this paper, we study observed variables that are a linear transformation of a linear latent causal model. Data from interventions are necessary for identifiability - if one latent variable is missing an intervention, we show that there exist distinct models that cannot be distinguished. Conversely, we show that a single intervention on each latent variable is sufficient for identifiability. Our proof uses a generalization of the RQ decomposition of a matrix that replaces the usual orthogonal and upper triangular conditions with analogues depending on a partial order on the rows of the matrix, with partial order determined by a latent causal model. We corroborate our theoretical results with a method for causal disentanglement that accurately recovers a latent causal model.","tags":["Causal Representation Learning","Interventions"],"title":"Linear Causal Disentanglement via Interventions","type":"publication"},{"authors":["Raj Agrawal","Chandler Squires","Neha Prasad","Caroline Uhler"],"categories":null,"content":"","date":1689206400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689206400,"objectID":"cdcb6471bab0086a052299bf73396bac","permalink":"/publication/2023/decamfounder/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2023/decamfounder/","section":"publication","summary":"Many real-world decision-making tasks require learning causal relationships between a set of variables. Typical causal discovery methods, however, require that all variables are observed, which might not be realistic in practice. Unfortunately, in the presence of latent confounding, recovering causal relationships from observational data without making additional assumptions is an ill-posed problem. Fortunately, in practice, additional structure among the confounders can be expected, one such example being pervasive confounding, which has been exploited for consistent causal estimation in the special case of linear causal models. In this paper, we provide a proof and consistent method to estimate causal relationships in the non-linear, pervasive confounding setting. The heart of our procedure relies on the ability to estimate the confounding variation through a simple spectral decomposition of the observed data matrix. We derive a DAG score function based on this insight, prove its consistency in recovering a correct ordering of the DAG, and empirically compare it to existing procedures. We show improved performance on both simulated and real datasets by explicitly accounting for both confounders and non-linear effects.","tags":["Causal Structure Learning","Unobserved Confounding"],"title":"The DeCAMFounder: Non-Linear Causal Discovery in the Presence of Hidden Variables","type":"publication"},{"authors":["Chandler Squires","Caroline Uhler"],"categories":null,"content":"","date":1659312000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659312000,"objectID":"6a108738bf4a5b7b31a32d13f48979e3","permalink":"/publication/2022/causal-structure-learning-review/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2022/causal-structure-learning-review/","section":"publication","summary":"In this review, we discuss approaches for learning causal structure from data, also called causal discovery. In particular, we focus on approaches for learning directed acyclic graphs (DAGs) and various generalizations which allow for some variables to be unobserved in the available data. We devote special attention to two fundamental combinatorial aspects of causal structure learning. First, we discuss the structure of the search space over causal graphs. Second, we discuss the structure of equivalence classes over causal graphs, i.e., sets of graphs which represent what can be learned from observational data alone, and how these equivalence classes can be refined by adding interventional data.","tags":["Causal Structure Learning"],"title":"Causal Structure Learning: a Combinatorial Perspective","type":"publication"},{"authors":["Chandler Squires","Dennis Shen","Anish Agarwal","Devavrat Shah","Caroline Uhler"],"categories":null,"content":"","date":1649635200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649635200,"objectID":"8b7b58ec4216b706afeef67f7b9c6091","permalink":"/publication/2022/causal-imputation/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2022/causal-imputation/","section":"publication","summary":"Consider the problem of determining the effect of a drug on a specific cell type. To answer this question, researchers traditionally need to run an experiment applying the drug of interest to that cell type. This approach is not scalable - given a large number of different actions (drugs) and a large number of different contexts (cell types), it is infeasible to run an experiment for every action-context pair. In such cases, one would ideally like to predict the result for every pair while only having to perform experiments on a small subset of pairs. This task, which we label \"causal imputation\", is a generalization of the causal transportability problem. In this paper, we provide two main contributions. First, we demonstrate the efficacy of the recently introduced *synthetic interventions* estimator on the task of causal imputation when applied to the prominent CMAP dataset. Second, we explain the demonstrated success of this estimator by introducing a generic *linear structural causal model* which accounts for the interaction between cell type and drug.","tags":["Imputation"],"title":"Causal Imputation via Synthetic Interventions","type":"publication"},{"authors":["Chandler Squires","Annie Yun","Eshaan Nichani","Raj Agrawal","Caroline Uhler"],"categories":null,"content":"","date":1649635200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649635200,"objectID":"59d469c74ad85e6afa30d88f97c18474","permalink":"/publication/2022/latent-factor-causal-models/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2022/latent-factor-causal-models/","section":"publication","summary":"We consider the problem of learning the structure of a causal directed acyclic graph (DAG) model in the presence of latent variables. We define \"latent factor causal models\" (LFCMs) as a restriction on causal DAG models with latent variables, which are composed of clusters of observed variables that share the same latent parent and connections between these clusters given by edges pointing from the observed variables to latent variables. LFCMs are motivated by gene regulatory networks, where regulatory edges, corresponding to transcription factors, connect spatially clustered genes. We show identifiability results on this model and design a consistent three-stage algorithm that discovers clusters of observed nodes, a partial ordering over clusters, and finally, the entire structure over both observed and latent nodes. We evaluate our method in a synthetic setting, demonstrating its ability to almost perfectly recover the ground truth clustering even at relatively low sample sizes, as well as the ability to recover a significant number of the edges from observed variables to latent factors. Finally, we apply our method in a semi-synthetic setting to protein mass spectrometry data with a known ground truth network, and achieve almost perfect recovery of the ground truth variable clusters.","tags":["Causal Structure Learning","Unobserved Confounding"],"title":"Causal Structure Discovery between Clusters of Nodes Induced by Latent Factors","type":"publication"},{"authors":["Michael Truell","Jan-Christian Hutter","Chandler Squires","Piotr Zwiernik","Caroline Uhler"],"categories":null,"content":"","date":1639958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639958400,"objectID":"850f8cabbb62f249b572aaecc038bb45","permalink":"/publication/2021/bmtm-mle/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2021/bmtm-mle/","section":"publication","summary":"We study the problem of maximum likelihood estimation given one data sample (n=1) over Brownian Motion Tree Models (BMTMs), a class of Gaussian models on trees. BMTMs are often used as a null model in phylogenetics, where the one-sample regime is common. Specifically, we show that, almost surely, the one-sample BMTM maximum likelihood estimator (MLE) exists, is unique, and corresponds to a fully observed tree. Moreover, we provide a polynomial time algorithm for its exact computation. We also consider the MLE over all possible BMTM tree structures in the one-sample case and show that it exists almost surely, that it coincides with the MLE over diagonally dominant M-matrices, and that it admits a unique closed-form solution that corresponds to a path graph. Finally, we explore statistical properties of the one-sample BMTM MLE through numerical experiments.","tags":["Causal Structure Learning"],"title":"Maximum Likelihood Estimation for Brownian Motion Tree Models Based on One Sample","type":"publication"},{"authors":["Jiaqi Zhang","Chandler Squires","Caroline Uhler"],"categories":null,"content":"","date":1638748800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638748800,"objectID":"98c934708dd71463aa3948162d6cd675","permalink":"/publication/2021/causal-mean-matching/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2021/causal-mean-matching/","section":"publication","summary":"Transforming a causal system from a given initial state to a desired target state is an important task permeating multiple fields including control theory, biology, and materials science. In causal models, such transformations can be achieved by performing a set of interventions. In this paper, we consider the problem of identifying a shift intervention that matches the desired mean of a system through active learning. We define the Markov equivalence class that is identifiable from shift interventions and propose two active learning strategies that are guaranteed to exactly match a desired mean. We then derive a worst-case lower bound for the number of interventions required and show that these strategies are optimal for certain classes of graphs. In particular, we show that our strategies may require exponentially fewer interventions than the previously considered approaches, which optimize for structure learning in the underlying causal graph. In line with our theoretical results, we also demonstrate experimentally that our proposed active learning strategies require fewer interventions compared to several baselines.","tags":["Experimental Design"],"title":"Matching a Desired Causal State via Shift Interventions","type":"publication"},{"authors":["Anastasiya Belyaeva","Louis Cammarate","Adityanarayanan Radhakrishnan","Chandler Squires","Karren Dai Yang","G.V. Shivashankar","Caroline Uhler"],"categories":null,"content":"","date":1613347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613347200,"objectID":"8afd3577a5d7e2a333a79ba7c5d9dc48","permalink":"/publication/2021/causal-networks-sars-cov2/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2021/causal-networks-sars-cov2/","section":"publication","summary":"Given the severity of the SARS-CoV-2 pandemic, a major challenge is to rapidly repurpose existing approved drugs for clinical interventions. While a number of data-driven and experimental approaches have been suggested in the context of drug repurposing, a platform that systematically integrates available transcriptomic, proteomic and structural data is missing. More importantly, given that SARS-CoV-2 pathogenicity is highly age-dependent, it is critical to integrate aging signatures into drug discovery platforms. We here take advantage of large-scale transcriptional drug screens combined with RNA-seq data of the lung epithelium with SARS-CoV-2 infection as well as the aging lung. To identify robust druggable protein targets, we propose a principled causal framework that makes use of multiple data modalities. Our analysis highlights the importance of serine/threonine and tyrosine kinases as potential targets that intersect the SARS-CoV-2 and aging pathways. By integrating transcriptomic, proteomic and structural data that is available for many diseases, our drug discovery platform is broadly applicable. Rigorous in vitro experiments as well as clinical trials are needed to validate the identified candidate drugs.","tags":["Causal Structure Learning"],"title":"Causal Network Models of SARS-CoV-2 Expression and Aging to Identify Candidates for Drug Repurposing","type":"publication"},{"authors":["Chandler Squires","Joshua Amaniampong","Caroline Uhler"],"categories":null,"content":"","date":1604534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604534400,"objectID":"70b17c9c8b6d3afdcd71f3c9aec85aff","permalink":"/publication/rfd-algorithm/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/rfd-algorithm/","section":"publication","summary":"The problem of learning a directed acyclic graph (DAG) up to Markov equivalence is equivalent to the problem of finding a permutation of the variables that induces the sparsest graph. Without additional assumptions, this task is known to be NP-hard. Building on the minimum degree algorithm for sparse Cholesky decomposition, but utilizing DAG-specific problem structure, we introduce an efficient algorithm for finding such sparse permutations. We show that on jointly Gaussian distributions, our method with depth $w$ runs in $O(p^{w+3})$ time. We compare our method with $w = 1$ to algorithms for finding sparse elimination orderings of undirected graphs, and show that taking advantage of DAG-specific problem structure leads to a significant improvement in the discovered permutation. We also compare our algorithm to *provably consistent* causal structure learning algorithms, such as the PC algorithm, GES, and GSP, and show that our method achieves comparable performance with a shorter runtime. Thus, our method can be used on its own for causal structure discovery. Finally, we show that there exist dense graphs on which our method achieves almost perfect performance, so that unlike most existing causal structure learning algorithms, the situations in which our algorithm achieves both good performance and good runtime are not limited to sparse graphs.","tags":["Causal Structure Learning"],"title":"Efficient Permutation Discovery in Causal DAGs","type":"publication"},{"authors":["Chandler Squires","Sara Magliacane","Kristjan Greenwald","Dmitriy Katz","Murat Kocaoglu","Karthikeyan Shanmugam"],"categories":null,"content":"","date":1604188800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604188800,"objectID":"d15f5af42864d2b2b1f28297bcf7c4c0","permalink":"/publication/2020/dct-policy/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2020/dct-policy/","section":"publication","summary":"A growing body of work has begun to study intervention design for efficient structure learning of causal directed acyclic graphs (DAGs). A typical setting is a causally sufficient setting, i.e. a system with no latent confounders, selection bias, or feedback, when the essential graph of the observational equivalence class (EC) is given as an input and interventions are assumed to be noiseless. Most existing works focus on worst-case or average-case lower bounds for the number of interventions required to orient a DAG. These worst-case lower bounds only establish that the largest clique in the essential graph could make it difficult to learn the true DAG. In this work, we develop a universal lower bound for single-node interventions that establishes that the largest clique is always a fundamental impediment to structure learning. Specifically, we present a decomposition of a DAG into independently orientable components through directed clique trees and use it to prove that the number of single-node interventions necessary to orient any DAG in an EC is at least the sum of half the size of the largest cliques in each chain component of the essential graph. Moreover, we present a two-phase intervention design algorithm that, under certain conditions on the chordal skeleton, matches the optimal number of interventions up to a multiplicative logarithmic factor in the number of maximal cliques. We show via synthetic experiments that our algorithm can scale to much larger graphs than most of the related work and achieves better worst-case performance than other scalable approaches.","tags":["Causal Structure Learning","Experimental Design"],"title":"Active Structure Learning of Causal DAGs via Directed Clique Trees","type":"publication"},{"authors":["Daniel Bernstein","Basil Saeed","Chandler Squires","Caroline Uhler"],"categories":null,"content":"","date":1571529600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571529600,"objectID":"6c0f2edc55f01d8ca98ea4437081dc43","permalink":"/publication/2020/gspo/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2020/gspo/","section":"publication","summary":"We consider the task of learning a causal graph in the presence of latent confounders given i.i.d. samples from the model. While current algorithms for causal structure discovery in the presence of latent confounders are constraint-based, we here propose a score-based approach. We prove that under assumptions weaker than faithfulness, any sparsest independence map (IMAP) of the distribution belongs to the Markov equivalence class of the true model. This motivates the \\emph{Sparsest Poset} formulation - that posets can be mapped to minimal IMAPs of the true model such that the sparsest of these IMAPs is Markov equivalent to the true model. Motivated by this result, we propose a greedy algorithm over the space of posets for causal structure discovery in the presence of latent confounders and compare its performance to the current state-of-the-art algorithms FCI and FCI+ on synthetic data.","tags":["Causal Structure Learning"],"title":"Ordering-Based Causal Structure Learning in the Presence of Latent Variables","type":"publication"},{"authors":["Chandler Squires","Yuhao Wang","Caroline Uhler"],"categories":null,"content":"","date":1571529600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571529600,"objectID":"43c6473f5ed541de555adec2858aed29","permalink":"/publication/2020/utigsp/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2020/utigsp/","section":"publication","summary":"We consider the problem of estimating causal DAG models from a mix of observational and interventional data, when the intervention targets are partially or completely unknown. This problem is highly relevant for example in genomics, since gene knockout technologies are known to have off-target effects. We characterize the interventional Markov equivalence class of DAGs that can be identified from interventional data with unknown intervention targets. In addition, we propose a provably consistent algorithm for learning the interventional Markov equivalence class from such data. The proposed algorithm greedily searches over the space of permutations to minimize a novel score function. The algorithm is nonparametric, which is particularly important for applications to genomics, where the relationships between variables are often non-linear and the distribution non-Gaussian. We demonstrate the performance of our algorithm on synthetic and biological datasets.","tags":["Causal Structure Learning"],"title":"Permutation-Based Causal Structure Learning with Unknown Intervention Targets","type":"publication"},{"authors":["Dmitriy Katz","Karthikeyan Shannmugan","Chandler Squires","Caroline Uhler"],"categories":null,"content":"","date":1551916800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551916800,"objectID":"d26fb11cb52a087a7ae5456a699e8d7a","permalink":"/publication/2019/sizes-of-imecs/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2019/sizes-of-imecs/","section":"publication","summary":"Directed acyclic graph (DAG) models are popular for capturing causal relationships. From observational and interventional data, a DAG model can only be determined up to its interventional Markov equivalence class (I-MEC). We investigate the size of MECs for random DAG models generated by uniformly sampling and ordering an ErdÅ‘s-RÃ©nyi graph. For constant density, we show that the expected.","tags":null,"title":"Size of Interventional Markov Equivalence Classes in Random DAG Models","type":"publication"},{"authors":["Raj Agrawal","Chandler Squires","Karren Yang","Karthikeyan Shanmugan","Caroline Uhler"],"categories":null,"content":"","date":1551225600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551225600,"objectID":"26b824180d0bf81b85200b944bac36e4","permalink":"/publication/2019/abcd-strategy/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2019/abcd-strategy/","section":"publication","summary":"Determining the causal structure of a set of variables is critical for both scientific inquiry and decision-making. However, this is often challenging in practice due to limited interventional data. Given that randomized experiments are usually expensive to perform, we propose a general framework and theory based on optimal Bayesian experimental design to select experiments for targeted causal discovery. That is, we assume the experimenter is interested in learning some function of the unknown graph (e.g., all descendants of a target node) subject to design constraints such as limits on the number of samples and rounds of experimentation. While it is in general computationally intractable to select an optimal experimental design strategy, we provide a tractable implementation with provable guarantees on both approximation and optimization quality based on submodularity. We evaluate the efficacy of our proposed method on both synthetic and real datasets, thereby demonstrating that our method realizes considerable performance gains over baseline strategies such as random sampling.","tags":["Experimental Design"],"title":"ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery","type":"publication"},{"authors":[],"categories":[],"content":"Welcome to Slides Academic\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nThemes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom CSS Example Letâ€™s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Yuhao Wang","Chandler Squires","Anastasiya Belyaeva","Caroline Uhler"],"categories":null,"content":"","date":1541548800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541548800,"objectID":"718bce8b92bb6b6e4c7fadeec589bd6a","permalink":"/publication/2018/difference-of-dags/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2018/difference-of-dags/","section":"publication","summary":"We consider the problem of estimating the differences between two causal directed acyclic graph (DAG) models with a shared topological order given i.i.d. samples from each model. This is of interest for example in genomics, where changes in the structure or edge weights of the underlying causal graphs reflect alterations in the gene regulatory networks. We here provide the first provably consistent method for directly estimating the differences in a pair of causal DAGs without separately learning two possibly large and dense DAG models and computing their difference. Our two-step algorithm first uses invariance tests between regression coefficients of the two data sets to estimate the skeleton of the difference graph and then orients some of the edges using invariance tests between regression residual variances. We demonstrate the properties of our method through a simulation study and apply it to the analysis of gene expression data from ovarian cancer and during T-cell activation.","tags":["Causal Structure Learning"],"title":"Direct Estimation of Differences in Causal Graphs","type":"publication"}]